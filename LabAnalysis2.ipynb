{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabAnalysis2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NYUExperimentalPhysics1-2021/LabAnalysis2/blob/main/LabAnalysis2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AuAie9jNGst"
      },
      "source": [
        "**In this assigmnent, you will add to existing code.** Each line you have to write has a numbered comment, so you won't miss one, CODE1, CODE2...CODE25\n",
        "\n",
        "**If something doesn't work the way you think it should,** please email the Professor and the TAs for help. This notebook started as working code; we removed lines to create the assignment. This process might have introduced an unexpected error. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBFO6nTSr9p1"
      },
      "source": [
        "As in other assignments, this first code block is meant to set things up. Below, modify the ```!git clone``` line so that the url points to your own data repository.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl2JqjsMqXUV"
      },
      "source": [
        "# necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, glob\n",
        "import scipy.optimize\n",
        "import itertools,operator\n",
        "\n",
        "# MODIFY THIS LINE SO THAT THE URL POINTS TO YOUR DATA REPOSITORY\n",
        "!git clone https://github.com/NYUExperimentalPhysics1-2021/lab2-data-repository-mgershow\n",
        "\n",
        "#this line makes sure you followed the direction above; if you see 20 copies of \"you didn't change the directory to match your name!\" that means you need to update the data repository name and clone again\n",
        "#delete my data repository (use folder icon on the left) or you will get this message again\n",
        "if os.path.isdir('lab2-data-repository-mgershow'):\n",
        "  for i in range(20):\n",
        "    print (\"You didn't change the directory to match your name!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9-yrTRqwKBW"
      },
      "source": [
        "These functions are needed to load the data, check that the data is valid (as in there aren't wild jumps in amplitude or period that would be due to measurement malfunctions), and return the largest sequences of valid data. Not important to know how they work, just how to run them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlyQoBQBZdzG"
      },
      "source": [
        "def findSlopeAndAmplitudeFiles (startdir):\n",
        "  #(slopeFiles, amplitudeFiles) = findSlopeAndAmplitudeFiles(startdir)\n",
        "  # input stardir: path to top level directory (e.g. data_repository/large bob)\n",
        "  # output slopeFiles: dictionary with paths to slope files, key names are taken from directories under large bob\n",
        "  #   e.g. if large bob has a directory 2mm, then\n",
        "  #   slopeFiles[\"2mm\"] is a list of paths to all slope files (end _slope.txt) \n",
        "  #   under this directory, even in subdirectories\n",
        "  # output amplitudeFiles: same as slopeFiles, but paths to all files ending _angle.txt\n",
        "  #https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python\n",
        "  #https://www.kite.com/python/answers/how-to-search-for-specific-files-in-subdirectories-in-python\n",
        "\n",
        "  slopeFiles = dict()\n",
        "  amplitudeFiles = dict()\n",
        "  for entry in os.scandir(startdir):\n",
        "    if (entry.is_dir):\n",
        "      key = entry.name\n",
        "      slopeFiles[key] = sorted(glob.glob(entry.path + '/**/*_slope.txt'))\n",
        "      amplitudeFiles[key] = sorted(glob.glob(entry.path + '/**/*_angle.txt'))\n",
        "      if (len(slopeFiles[key]) != len(amplitudeFiles[key])):\n",
        "        print(\"Warning! \" + key + \" does not contain same number of slope and angle files\")\n",
        "  return (slopeFiles, amplitudeFiles)\n",
        "\n",
        "# needed to check data validity\n",
        "# returns the indices of the first and last element of the largest sequence of true in a list of booleans\n",
        "def longestTrueSequence(seq):\n",
        "  #adapted from https://stackoverflow.com/questions/40166522/find-longest-sequence-of-0s-in-the-integer-list\n",
        "  r = max((list(y) for (x,y) in itertools.groupby((enumerate(seq)),operator.itemgetter(1)) if x), key=len)\n",
        "  return (r[0][0], r[-1][0])\n",
        "\n",
        "# Checking data validity (no wild outliers)\n",
        "# returns longest sequence of valid data\n",
        "def sanityCheck(time, y, number):\n",
        "  dt = np.diff(time)\n",
        "  dly = np.diff(np.abs(np.log(y)))\n",
        "  dn = np.diff(number)\n",
        "  maxperiod = 5 #equivalent to 6 meter pendulum\n",
        "  maxchange = np.log(1.5) #don't allow an INCREASE of more than 50%\n",
        "  valid = ((dt > 0) & (dt < maxperiod) & (dly < maxchange) & (dn > 0) & (dn <= 2))\n",
        "  (start,stop) = longestTrueSequence(valid)\n",
        "  if start > 0:\n",
        "    start = start+1\n",
        "  time = time[start:stop+1]\n",
        "  y = y[start:stop+1]\n",
        "  number = number[start:stop+1]\n",
        "  return(time,y,number)\n",
        "\n",
        "# load slope and get longest valid sequence\n",
        "# takes the absolute value of slope \n",
        "# inputs: filepath - path of the file\n",
        "#         maxTime - optional, longest duration to load\n",
        "# outputs: time - time of the crossing\n",
        "#          slope - absolute value of slope at each crossing\n",
        "#          number - index of crossing, should increase by 1 each step\n",
        "def loadSlopeFile(filepath, maxTime = 10000000):\n",
        "  time, slope, number = np.loadtxt(filepath, skiprows = 1, unpack=True)\n",
        "  time,slope,number = sanityCheck(time,np.abs(slope),number)\n",
        "  valid = time-time[0] <= maxTime\n",
        "  time = time[valid]\n",
        "  slope = slope[valid]\n",
        "  number = number[valid]\n",
        "  return (time,slope,number)\n",
        "\n",
        "# load amplitude and get longest valid sequence\n",
        "# inputs: filepath - path of the file\n",
        "#         maxTime - optional, longest duration to load\n",
        "# outputs: time - time of the crossing\n",
        "#          amplitude - absolute value of amplitude fit to the complete ellipse centered on the crossing\n",
        "#          number - index of crossing, should increase by 2 each step\n",
        "def loadAmpltidueFile(filepath, maxTime = 10000000):\n",
        "  time, theta, amplitude, minaxis, number = np.loadtxt(filepath, skiprows = 1, unpack = True)\n",
        "  time,amplitude,number = sanityCheck(time,np.abs(amplitude),number)\n",
        "  valid = time-time[0] <= maxTime\n",
        "  time = time[valid]\n",
        "  amplitude = amplitude[valid]\n",
        "  number = number[valid]\n",
        "  return (time, amplitude, number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2xLlcEjwq_V"
      },
      "source": [
        "These functions do the equation fitting, and you should try to familiarize yourself with how fitting works. These will be used to fit your data to exponential and linear curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl8RA_5ewqH4"
      },
      "source": [
        "# fitting an exponential\n",
        "# exponential has two parameters, the y-intercept (a) and the\n",
        "# exponential multiplier constant (b which for our purposes is -1/tau)\n",
        "# inputs: x,y - numpy arrays\n",
        "# outputs: a: fit value of y(0)\n",
        "#          b: fit value of exonent\n",
        "#          fity: a * e^(bx) \n",
        "def fitExponential(x,y):\n",
        "  xx = x - np.min(x)\n",
        "  yy = y / np.max(y)\n",
        "  fitparams, *_ = scipy.optimize.curve_fit(lambda xdata, a, b : a*np.exp(b * xdata), xx, yy, (1, -1/max(xx)))\n",
        "  a,b = fitparams\n",
        "  a = a*np.max(y)*np.exp(-b*np.min(x))\n",
        "  return (a,b, a*np.exp(b*x))\n",
        "\n",
        "# fitting a line\n",
        "# line is polynomial of degree 1\n",
        "# two free parameters, the slope and the y intercept\n",
        "# inputs: x,y - numpy arrays\n",
        "# outputs: slope (m): fit value of slope\n",
        "#          intercept (b): fit value of intercept (y(0))\n",
        "#          fity: m*x + b\n",
        "def fitLine(x,y):\n",
        "  p = np.polyfit(x,y,1)\n",
        "  slope = p[0]\n",
        "  intercept = p[1]\n",
        "  return (slope, intercept, slope*x + intercept)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq25hOc2yE5Z"
      },
      "source": [
        "The below block shows an example of how to load the data for the large bob. This will create two [dictionaries](https://physics.nyu.edu/pine/pymanual/html/chap3/chap3_arrays.html#dictionaries), ```largeSlope``` and ```largeAmplitude```, which contain the displacement as the key and the data from the text file as the value. In order to load the data, you will need to know the file structure of your repository and give the ```findSlopeAndAmplitudeFiles()``` function the proper path to the displacement folders. For example, ```'lab2-data-repository-mgershow/'``` is the top level folder and ```'large bob'``` is the next-level folder that contains all of the displacement folders ```'2mm'```, ```'3mm'```, ```'4mm'```, and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDPezAOMeUiO"
      },
      "source": [
        "# loading data, need to know file structure of repository\n",
        "largeSlope, largeAmplitude = findSlopeAndAmplitudeFiles('lab2-data-repository-mgershow/large bob')\n",
        "\n",
        "#uncomment this line if you are also ready to analyze small bob data\n",
        "#smallSlope, smallAmplitude = findSlopeAndAmplitudeFiles('lab2-data-repository-mgershow/small bob')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVvBvSjL0ZKq"
      },
      "source": [
        "## Energy vs time - individual traces and fits\n",
        "\n",
        "For three distributed distances of the large bob from the plate (e.g. 3 mm, 6 mm, 9 mm)\n",
        "\n",
        "1. Make a new figure\n",
        "1. Make 2 subplots side by side.\n",
        "1. In the left subplot, plot the **slope** vs. time since the start of the measurement (time - time[0]) of each dataset on the same graph. Make the [y-axis logarithmic](https://physics.nyu.edu/pine/pymanual/html/chap5/chap5_plot.html#logarithmic-plots). The data should look like a straight line\n",
        "1. For each experiment you plotted, calculate an exponential fit to the data and store the lifetime (the fit gives you a and b in the equation $s = a e^{b t}$, and $\\tau = -\\frac{1}{b}$). Store the calculated lifetime in a list called slope_lifetime.\n",
        "1. Title the plot with the mean and standard deviation of the lifetimes.\n",
        "1. In the right subplot, do the same thing but with the **amplitude squared**\n",
        "\n",
        "\n",
        "We've done a lot of this work for you - you will need to fill in the parts indicated by comments below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGUvLlTTm0Ou"
      },
      "source": [
        "for expt_set_dir in [\"3 mm\", \"6 mm\", \"9 mm\"]: #replace with your own directory names\n",
        "  slope_lifetime = []\n",
        "  ampsq_lifetime = []\n",
        "  plt.figure()\n",
        "  plt.subplot(1, 2, 1)\n",
        "  for file in largeSlope[expt_set_dir]:\n",
        "    time, slope, number = loadSlopeFile(file)\n",
        "    #CODE1: use plt.semilogy to make a plot of time-time[0] on the linear x-axis vs. slope on the logarithmic y-axis   \n",
        "    a,b,*_ = fitExponential(time-time[0], slope)  #use *_ to discard unwanted return values (in this case the fit y-data)\n",
        "    slope_lifetime.append( )#CODE2: modify this line to add -1/b (the fit lifetime) to the slope_lifetime list\n",
        "  mu = #CODE3: calculate the mean of slope_lifetime\n",
        "  sigma = np.std(slope_lifetime, ddof=1) #calculates the standard deviation using N-1 in the deonminator\n",
        "  plt.title (r'$\\mu$ = {:.1f}s, $\\sigma$ = {:.1f}s'.format(mu, sigma))\n",
        "  \n",
        "  \n",
        "  plt.subplot(1, 2, 2)\n",
        "  for file in largeAmplitude[expt_set_dir]:\n",
        "    time, amp, number = loadAmpltidueFile(file)\n",
        "    #CODE4: use plt.semilogy to make a plot of time-time[0] on the linear x-axis vs. amplitude SQUARED on the logarithmic y-axis   \n",
        "    a,b,*_ = #CODE5: complete to calculate the exponential fit of amp squared to time-time[0] hint: see very similar code above! \n",
        "    ampsq_lifetime.append(-1/b)\n",
        "  mu =  #CODE6: calculate the mean of slope_lifetime\n",
        "  sigma = np.std(ampsq_lifetime, ddof=1)\n",
        "  plt.title (r'$\\mu$ = {:.1f}s, $\\sigma$ = {:.1f}s'.format(mu, sigma))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtk683LP-YW8"
      },
      "source": [
        "##QUESTIONS - answer below \n",
        "\n",
        "1. What evidence do you have that the energy decays exponentially (or that it does not)?\n",
        "2. Are the slope and amplitude measurements consistent with each other?\n",
        "3. Based on a visual examination of the graphs, which measurement of the energy of the bob has more noise (slope or amplitude squared)\n",
        "4. Based on the standard deviation of the lifetime measurements, which measurement of the lifetime (fit to slope or fit to amplitude squared) has less experimental error?\n",
        "5. If you find that these results disagree unexpectedly, look at the x-axes of the plots. Do the slope and amplitude data cover the same time ranges? The loading function automatically tries to discard noisy data. Does this explain why the slope measurements are shorter than the amplitude measurements?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n37SVsBkBjug"
      },
      "source": [
        "## Energy vs time - fixed time range\n",
        "\n",
        "Copy and paste your solution in the code box below. Let's modify it a little so that each experiment covers roughly the same time range within an experimental condition.\n",
        "\n",
        "The load commands take an optional argument, maxTime that cuts the length of the loaded data to that time range (or shorter if the full range isn't available). Let's redo the excercise above, limiting the time range to 1.5 lifetimes. \n",
        "\n",
        "We have to iterate in a slightly different way, so we've written the for loop structure for you - it's your job to fill in the rest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_X67UaD93fh"
      },
      "source": [
        "expt_set_dirs =  [\"3 mm\", \"6 mm\", \"9 mm\"] #replace with your own directory names\n",
        "lifetime = [12.6, 29, 91] #replace with the lifetimes you measured above\n",
        "for i in range(3):\n",
        "  expt_set_dir = expt_set_dirs[i]\n",
        "  slope_lifetime = []\n",
        "  ampsq_lifetime = []\n",
        "  plt.figure()\n",
        "  plt.subplot(1, 2, 1)\n",
        "  for file in largeSlope[expt_set_dir]:\n",
        "    time, slope, number = loadSlopeFile(file, lifetime[i]*1.5)\n",
        "    #CODE7: three lines of code that do an exponential fit, semilog plot, and add lifetime to list\n",
        "  #CODE8: two lines of code that calculate mean and standard deviation\n",
        "  plt.title (r'$\\mu$ = {:.1f}s, $\\sigma$ = {:.1f}s'.format(mu, sigma))\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  for file in largeAmplitude[expt_set_dir]:\n",
        "    time, amp, number = loadAmpltidueFile(file, lifetime[i]*1.5)\n",
        "    #CODE9: three lines of code that do an exponential fit, semilog plot, and add lifetime to list\n",
        "  #CODE10: two lines of code that calculate mean and standard deviation\n",
        "  plt.title (r'$\\mu$ = {:.1f}s, $\\sigma$ = {:.1f}s'.format(mu, sigma))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mCenzMaF_1v"
      },
      "source": [
        "##QUESTIONS - answer below\n",
        "1. Did shortenting the time range change which method of lifetime measurement had less error?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccoQN0JWF8D3"
      },
      "source": [
        "## Energy vs time - let's look again\n",
        "\n",
        "If your data looks like mine (and it may not!), there's a bit of a paradox, the slope measurement looks \"noisier\" - the energy bounces around a lot more from swing to swing - but the lifetime measurement is more consistent from experiment to experiment. Let's have one last look.\n",
        "\n",
        "Copy your entire code block from above. Make one change: instead of plotting slope or amplitude^2 vs. time, plot slope/a (or amplitude^2/a) vs. time, where a is the fit parameter for slope(t = 0) from your exponential fits. This will make curves with the same lifetimes look identical. \n",
        "\n",
        "Hint: change the order, so you first calculate the fit, then make the plot, like this\n",
        "\n",
        "```\n",
        "  a,b,*_ = fitExponential(time-time[0], slope) \n",
        "  plt.semilogy(time-time[0], slope/a)\n",
        "```\n",
        "\n",
        "double hint: this hint may give away an answer to a previous question\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrGPEbPWHr0b"
      },
      "source": [
        "expt_set_dirs =  [\"3 mm\", \"6 mm\", \"9 mm\"] #replace with your own directory names\n",
        "lifetime = [12.6, 29, 91] #replace with the lifetimes you measured above\n",
        "for i in range(3):\n",
        "  expt_set_dir = expt_set_dirs[i]\n",
        "  slope_lifetime = []\n",
        "  ampsq_lifetime = []\n",
        "  plt.figure()\n",
        "  plt.subplot(1, 2, 1)\n",
        "  for file in largeSlope[expt_set_dir]:\n",
        "    time, slope, number = loadSlopeFile(file, lifetime[i]*1.5)\n",
        "    #CODE11: three lines of code that do an exponential fit, semilog plot (with slope scaled by 1/a), and add lifetime to list\n",
        "  #CODE12: two lines of code that calculate mean and standard deviation\n",
        "  plt.title (r'$\\mu$ = {:.1f}s, $\\sigma$ = {:.1f}s'.format(mu, sigma))\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  for file in largeAmplitude[expt_set_dir]:\n",
        "    time, amp, number = loadAmpltidueFile(file, lifetime[i]*1.5)\n",
        "    #CODE12: three lines of code that do an exponential fit, semilog plot (with amplitude squared scaled by 1/a), and add lifetime to list\n",
        "  #CODE13: two lines of code that calculate mean and standard deviation\n",
        "  plt.title (r'$\\mu$ = {:.1f}s, $\\sigma$ = {:.1f}s'.format(mu, sigma))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Y2eYWPGezN"
      },
      "source": [
        "##Questions - answer below\n",
        "\n",
        "1. Based on these graphs, should you use slope or amplitude squared to measure the lifetime of the bob?\n",
        "2. What is it called when a measurement has errors that aren't random? Do you think either the slope or amplitude measurements have these kinds of errors?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKwPtN83-KDB"
      },
      "source": [
        "#Lifetime vs. separation\n",
        "\n",
        "OK, now let's look at the whole data set. We want to find a relation between the separation and the lifetime. \n",
        "\n",
        "We need to do the following:\n",
        "1. Make a list of all the directories we want analyzed\n",
        "1. Define a numerical value of the height for each directory. \n",
        "1. Loop over all the directories. For each directory\n",
        "  1. Calculate the lifetime from each experiment. I'm using slope, because I think it was more reliable in my data set. You can use amplitude squared if you think that's better. Justify your choice. \n",
        "  1. Find the mean and standard deviation of these lifetimes. \n",
        "  1. Calculate the standard error of the mean as the standard deviation over the square root of the number of measurements\n",
        "1. Make an [error bar plot](https://physics.nyu.edu/pine/pymanual/html/chap5/chap5_plot.html#error-bars) of lifetime vs. separation. My error bars were small enough they were hard to see. How about yours?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iHwxA9qCB1i"
      },
      "source": [
        "lg_dir = (\"2mm\", \"3 mm\", \"4 mm\", \"5 mm\", \"6 mm\", \"7 mm\", \"8 mm\", \"9 mm\") #replace with your directory names\n",
        "lg_h = np.array((2,3,4,5,6,7,8,9),'float') #replace with your distances\n",
        "maxtime = [-1] * len(lg_dir) #[-1, -1, -1, -1, -1, -1, -1, -1, -1] - you can explicitly define times for some or all directories if the default of 1.5 lifetimes isn't good for you\n",
        "\n",
        "#initialize numpy arrays\n",
        "lg_tau = lg_h*0.;\n",
        "lg_tau_sigma = lg_h*0.;\n",
        "lg_tau_sem = lg_h*0.;\n",
        "\n",
        "for i in range(len(lg_dir)):\n",
        "    key = lg_dir[i]\n",
        "    lifetime = []\n",
        "    #if maxtime isn't defined, then calculate lifetime and use 1.5 lifetimes as the max time\n",
        "    if (maxtime[i] <= 0):\n",
        "      for file in largeSlope[key]:\n",
        "        time, slope, number = loadSlopeFile(file)\n",
        "        if (len(time) > 4):\n",
        "          #CODE 14: two lines, calculate exponential fit of slope to time - time[0] and append -1/b to lifetime list\n",
        "      initial_lifetime = np.median(lifetime)\n",
        "      maxtime[i] = initial_lifetime*1.5\n",
        "      lifetime = []\n",
        "\n",
        "    for file in largeSlope[key]:  \n",
        "      time, slope, number = loadSlopeFile(file, maxTime = maxtime[i])\n",
        "      if (len(time) > 4):\n",
        "        a,b,*_ = fitExponential(time-time[0], slope)\n",
        "        lifetime.append(-1/b)\n",
        "    lg_tau[i] =  #CODE 15: calculate mean of lifetime list\n",
        "    lg_tau_sigma[i] = np.std(lifetime,ddof=1)\n",
        "    lg_tau_sem[i] = #CODE 16: lg_tau_sigma[i] / square root of the number of elements in the lifetime list\n",
        "   \n",
        "#CODE17: use plt.errorbar to makea plot of lg_tau vs. tg_h with yerr of lg_tau_sem\n",
        "#CODE18: add title (lifetime vs. separation) xlabel (separation(mm)) and ylabel (lifetime(s)). hint add a ; to the end of the last line to eliminate the annoying text message in the output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcX99ZnFsXWU"
      },
      "source": [
        "##Fit lifetime vs. height to a power law\n",
        "\n",
        "if $\\tau = a h^b$, then $\\log(\\tau) = b \\log(h) + \\log(a)$ \n",
        "\n",
        "in other words, a log-log graph will look like a straight line\n",
        "\n",
        "use the plt.loglog command to plot lifetime (tau) vs separation (lg_h)\n",
        "\n",
        "use 'bo-' (blue circles connectd by lines) for the line type\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-aAPgrVtKaU"
      },
      "source": [
        "#CODE 19: log-log plot of lifetime vs. separation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_hXwEXUthNW"
      },
      "source": [
        "##Fit lifetime vs. height to a power law, take 2\n",
        "\n",
        "If your data is like mine, this doesn't look like a very straight line. The problem is that the real form is probably something like \n",
        "\n",
        "$\\tau = a (h + h_0)^b$, and $\\log(\\tau) = b \\log(h+h_0) + \\log(a)$ \n",
        "\n",
        "where $h_0$ is some offset due to the thickness of the magnet and the aluminum plate. The magnet is 3/16\" thick and the plate is 1/8\" thick. Together, that's about 8mm of thickness, and the distance between their centers is therefore 4 mm. \n",
        "\n",
        "try putting in an offset of 4 mm (plot tau vs. h + 4) and see if it looks more like a straight line. hint, you will have to convert lg_h to a numpy array before you can add 4. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_0XXfrRgcDX"
      },
      "source": [
        "#CODE 20: log-log plot of lifetime vs. separation + 4 mm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLbK3UmxyWiZ"
      },
      "source": [
        "##Well that looks good, but....\n",
        "\n",
        "Now do the same things for offsets of 3 and 5 mm... Do you still see a straight line?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S2xnr7Xyvni"
      },
      "source": [
        "#CODE 21: two lines: log-log plots of lifetime vs. separation + 3mm and + 5mm, one in red and one in blue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqvlnN5QzBBV"
      },
      "source": [
        "## Use the residuals to find the most likely value of the separation\n",
        "\n",
        "The residuals (the difference of the measured value from the fit value) can be used to tell you the quality of a fit. Assuming each measurement has equal error, the best fit is the one that minimizes the sum of the square of the residuals\n",
        "\n",
        "minimize $\\sum_h(\\tau(h) - \\tau_{fit}(h))^2$\n",
        "\n",
        "below, I've written a function that calculates the sum of the squared residuals for a power law fit, given some offset $h_0$.  Then I make a graph of this sum vs. my guess of $h_0$ \n",
        "\n",
        "I need you to write a few lines for me\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkH8usifkxbJ"
      },
      "source": [
        "def powerLawResidualSqSum(h, tau, h0):\n",
        "  x = np.log(h + h0)\n",
        "  y = np.log(tau)\n",
        "  m,b,yfit = fitLine(x,y)\n",
        "  tau_fit = np.exp(yfit)\n",
        "  return #CODE 22: sum of tau - tau_fit squared \n",
        "\n",
        "offset = np.arange(1,10,.1)\n",
        "residsq = offset*0\n",
        "for i in range(len(offset)):\n",
        "  residsq[i] = #CODE 23: use the function above to calculate the residual for lg_h, lg_tau and offset[i] \n",
        "plt.plot(offset, residsq);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvVPJ6I1X16"
      },
      "source": [
        "By eye, you might be able to find the best guess for h0, but we can actually ask python to find the true minimum, using scipy.optimize. We'll worry about how this works later, but for now just run the code block below to find the minimum "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuCN8ijsiweD"
      },
      "source": [
        "res = scipy.optimize.minimize(lambda h : powerLawResidualSqSum(lg_h, lg_tau,h), 5)\n",
        "h0 = res.x[0]\n",
        "rsq = res.fun\n",
        "plt.plot(offset, residsq, 'b-', h0, rsq, 'm*')\n",
        "plt.xlabel ('separation offset')\n",
        "plt.ylabel ('sum of residuals squared');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHcsmbQe2QTH"
      },
      "source": [
        "Finally, using the best value of the separation (h0) you calculated above, find the power law exponent and plot the data and the fit for lifetime vs. separation together. \n",
        "\n",
        "Then, in another figure, plot the residuals with the error bars of the measurements.. x:lg_h, y: lg_tau - $\\tau_{fit}$, error bars: lg_tau_sem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBtG_fBVja-L"
      },
      "source": [
        "x = np.log(np.array(lg_h) + hmin)\n",
        "y = np.log(lg_tau)\n",
        "\n",
        "m,b,yfit = #CODE 24: fit to a line y = mx + b\n",
        "lg_taufit = np.exp(yfit)\n",
        "\n",
        "#CODE 25: plot lg_tau vs. lg_h with blue circles and lg_taufit vs lg_h with a black dashed line \n",
        "plt.plot(lg_h, lg_tau,  'bo', lg_h, np.exp(yfit), 'k--')\n",
        "plt.xlabel('separation (mm)')\n",
        "plt.ylabel('lifetime (s)')\n",
        "plt.title('tau ~ (h + {:.2f})^{:.1f}'.format(hmin, m) );\n",
        "\n",
        "plt.figure()\n",
        "#CODE 26: error bar plot of lg_tau-lg_taufit vs. lg_h, yerr = lg_tau_sem\n",
        "plt.xlabel('separation (mm)')\n",
        "plt.ylabel('residuals and sem (s)')\n",
        "\n",
        "#Add a black dashed line across the x-axis by plotting lg_h*0 vs lg_h. \n",
        "plt.plot(lg_h, lg_h*0, 'k--');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TVctinx24sh"
      },
      "source": [
        "#Small bob time!\n",
        "\n",
        "Please reuse the analysis steps you did above to make a plot of lifetime vs separation for the small bob, along with a power law fit.\n",
        "\n",
        "Then make two additional plots\n",
        "1. Plot lifetime vs. separation for the large and small bobs on the same graph. Use blue circles for the large bob and red circles for the small bob. Add a legend to the plot.\n",
        "2. Make the same plot, but this time, multiply the small bob lifetime by (4/3)^3. Does this analysis support the relation $\\tau \\propto m_{bob}$?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbJ3OWHN425w"
      },
      "source": [
        "#A few more questions\n",
        "\n",
        "The total energy of the bob is $E = \\frac{1}{2} m (A * 2\\pi / T)^2$, where $m$ is the mass, $A$ is the amplitude, and $T$ is the period. The rate of energy loss is $-\\frac{dE}{dt} = E/\\tau$, where $\\tau$ is the lifetime. For the large bob, please calculate the following, to 1 significant figure (e.g. 10 J, not 10.231 J)\n",
        "1. The total energy when A = 10 cm\n",
        "1. The total energy when A = 1 cm\n",
        "1. The rate of energy loss for a separation of 2 mm, when A = 10 cm and A = 1 cm\n",
        "1. The rate of energy loss for a separation of 10 mm (or whatever your maximum separation was), when A = 10 cm and A = 1 cm\n"
      ]
    }
  ]
}